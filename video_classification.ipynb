{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Classification\n",
    "\n",
    "Video classification is one capability among many under the broad umbrella of _video understanding_, technologies that automatically extract information from video. You can read more about the great, wide world of video understanding in our blog post [here](https://www.notion.so/fastforwardlabs/December-2021-ccbd4d6633dc40d0b329c41f71bb6406#f6e2430cacdb434ea7fef5d4a1535ce4). Video classification is one of the fundamental building blocks used in a slew of video understanding tasks. Its goal is to identify the action or motion within a video. This capability is similar to image clasification but with a twist -- models must not only detect the cat, but also what the cat is _doing_. \n",
    "\n",
    "The goal of this notebook is to provide an introduction to video classification, including datasets, models, and methods used for video classification and action recognition. Specifically, we'll explore the Kinetics video dataset and the pre-trained I3D model for action recognition, hosted on the Tensorflow Model Hub. This notebook requires Tensorflow as well as a few other packages, which we install below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "#hides cell output. disable for logs.\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "code",
    "id": "USf0UvkYIlKo"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make it easier to work with the dataset and model in this notebook, we created a small library of helper functions and classes. Here, we import the good bits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vidbench.data.load import KineticsLoader\n",
    "from vidbench.models import I3DLoader\n",
    "from vidbench.predict import predict, store_results_in_dataframe, compute_accuracy, evaluate\n",
    "from vidbench.visualize import make_video_table\n",
    "from vidbench.data.process import resample_video, load_and_resize_video, video_acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this notebook does not require a GPU to run (we only process a few videos for demonstration purposes), if you have GPUs at your disposal you can check them here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "In this notebook we make use of the DeepMind [Kinetics dataset](https://arxiv.org/abs/1705.06950), which consists of thousands of YouTube videos focused on human actions and interactions. While there are several versions of this dataset, we'll focus primarily on the Kinetics 400 dataset which contains 400 human action classes, ranging from human-object interactions like playing instruments, as well as human-human interactions like shaking hands. Each video clip is approximately ten seconds and has been sourced from a unique YouTube video.   \n",
    "\n",
    "\n",
    "As of November 2021, the video files that make up the Kinetics datasets are stored at https://s3.amazonaws.com/kinetics/ as described in this [repository](https://github.com/cvdfoundation/kinetics-dataset). The Kinetics 400 contains a total of 306,245 video clips with at least 400 clips in each class.  These are distributed among three splits: training, test and validation. Each split consists of thousands of videos in `.mp4` format. \n",
    "\n",
    "| Dataset split | Clips per class | Total Videos |\n",
    "|---------------|-----------------|--------------|\n",
    "| train         |  250-1000       |    246245    |\n",
    "| test          |   100           |   40000      |\n",
    "| val           |     50          |   20000      |\n",
    "\n",
    "\n",
    "For each dataset split, videos are grouped into a series of directories and each directory is packaged as a `tar.gz` file that needs to be unpacked. Each of these `tar.gz` files contains about 1000 video clips.  In this notebook we'll explore a handful of videos from the validation set and we created a `KineticsLoader` class to handle downloading and unpacking these video files.  While this class is designed to handle the full validation (or test, or train) set, we can also use it to explore a small portion of the videos, which we'll demonstrate in the following cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No need to fetch, path already exists /home/cdsw/data/raw/kinetics/400/val/k400_val_path.txt\n",
      "No need to fetch, path already exists /home/cdsw/data/raw/kinetics/400/val/val.csv\n"
     ]
    }
   ],
   "source": [
    "# this class handles the infrastructure to support downloading, unpacking, and pre-processing videos\n",
    "loader = KineticsLoader(version=\"400\", split=\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're exploring this notebook after performing automatic setup through the CML AMP interface, then we've already downloaded a chunk of videos to explore. If not, running the cell below will initiate a download and unpacking of (at least) 500 vidoes (recall that they are grouped in chunks of approximately 1000). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.download_n_videos(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the code above we've downloaded just 1000 videos from the validation set (out of 20,000 available videos). We could download the entire validation set but that would require at least 30-50 GBs of storage! Since our goal in this notebook is simply to explore the video classification capability, 1000 videos is more than enough to explore with. This AMP also includes a benchmarking script that will allow the user to evaluate a model on _all_ videos in any of the data splits discussed above (more on this towards the end of the notebook).   \n",
    "\n",
    "We've also downloaded the ground truth labels for _all_ 20K videos in the validation set. These are stored in a Pandas DataFrame which you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>youtube_id</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "      <th>split</th>\n",
       "      <th>is_cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abseiling</td>\n",
       "      <td>0wR5jVB-WPk</td>\n",
       "      <td>417</td>\n",
       "      <td>427</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abseiling</td>\n",
       "      <td>3caPS4FHFF8</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abseiling</td>\n",
       "      <td>3yaoNwz99xM</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abseiling</td>\n",
       "      <td>6IbvOJxXnOo</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abseiling</td>\n",
       "      <td>6_4kjPiQr7w</td>\n",
       "      <td>191</td>\n",
       "      <td>201</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19901</th>\n",
       "      <td>zumba</td>\n",
       "      <td>w5hbJLVhZDI</td>\n",
       "      <td>93</td>\n",
       "      <td>103</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19902</th>\n",
       "      <td>zumba</td>\n",
       "      <td>xDd6uIBeMEA</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19903</th>\n",
       "      <td>zumba</td>\n",
       "      <td>XWvGn7eI04A</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19904</th>\n",
       "      <td>zumba</td>\n",
       "      <td>yGdQwxP5koA</td>\n",
       "      <td>83</td>\n",
       "      <td>93</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19905</th>\n",
       "      <td>zumba</td>\n",
       "      <td>ZVDR2od1gn8</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19906 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label   youtube_id  time_start  time_end split  is_cc\n",
       "0      abseiling  0wR5jVB-WPk         417       427   val      0\n",
       "1      abseiling  3caPS4FHFF8          36        46   val      0\n",
       "2      abseiling  3yaoNwz99xM          62        72   val      1\n",
       "3      abseiling  6IbvOJxXnOo          47        57   val      0\n",
       "4      abseiling  6_4kjPiQr7w         191       201   val      0\n",
       "...          ...          ...         ...       ...   ...    ...\n",
       "19901      zumba  w5hbJLVhZDI          93       103   val      0\n",
       "19902      zumba  xDd6uIBeMEA           1        11   val      0\n",
       "19903      zumba  XWvGn7eI04A          12        22   val      0\n",
       "19904      zumba  yGdQwxP5koA          83        93   val      0\n",
       "19905      zumba  ZVDR2od1gn8          37        47   val      0\n",
       "\n",
       "[19906 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_labels_df = pd.read_csv(f\"{loader.data_dir}/val.csv\")\n",
    "ground_truth_labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this DataFrame has nearly 20K rows - one for each video clip in the validation set. We need to filter this DataFrame to just those videos that we've actually downloaded. Our `KineticsLoader` keeps track of which videos we've downloaded. We can see all available pathnames with the following line. We're only showing the top 20 but there are 1000 video pathnames available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/cdsw/data/raw/kinetics/400/val/part_0/0tlGOxUQ0Kw_000074_000084.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-05qSkAhM6Y_000205_000215.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-LISB_b8rIw_000049_000059.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/--ILYNHl3e4_000541_000551.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-yv8c2CDbR8_000004_000014.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-aeOuOI3eN0_000219_000229.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-WZgMWx8Elk_000013_000023.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-Y-fUYGcb7o_000049_000059.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-beyXnxwTao_000040_000050.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-whdHn9Mbcc_000000_000010.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-CAPalSW0QI_000546_000556.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/0HydDezkSU0_000018_000028.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-4hx9N2OhZo_000029_000039.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-PW6kckornM_000008_000018.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-Wx7UjNi3uU_000010_000020.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/0dwPQPV3iYQ_000039_000049.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-0r6NmrdKCU_000043_000053.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/0Lx_B0Xg3kU_000007_000017.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-5vr1M9jygc_000100_000110.mp4',\n",
       " '/home/cdsw/data/raw/kinetics/400/val/part_0/-AMpy1HyBfk_000261_000271.mp4']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.video_filenames[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll filter the ground truth DataFrame to include only those vidoes that have already been downloaded and are available locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_youtube_ids = []\n",
    "for filename in loader.video_filenames:\n",
    "    pathname, vidname = os.path.split(filename)\n",
    "    available_youtube_ids.append(vidname[:11]) #youtube IDs are 11 characters long\n",
    "\n",
    "available_videos_metadata_df = ground_truth_labels_df[ground_truth_labels_df['youtube_id'].isin(available_youtube_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>youtube_id</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "      <th>split</th>\n",
       "      <th>is_cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abseiling</td>\n",
       "      <td>0wR5jVB-WPk</td>\n",
       "      <td>417</td>\n",
       "      <td>427</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>air drumming</td>\n",
       "      <td>--nQbRBEz2s</td>\n",
       "      <td>104</td>\n",
       "      <td>114</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>answering questions</td>\n",
       "      <td>-egPJubR-CE</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>answering questions</td>\n",
       "      <td>-ejLPB4J4SM</td>\n",
       "      <td>106</td>\n",
       "      <td>116</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>answering questions</td>\n",
       "      <td>-emx5qjikEc</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19811</th>\n",
       "      <td>yoga</td>\n",
       "      <td>-Gb1pbOE32g</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19812</th>\n",
       "      <td>yoga</td>\n",
       "      <td>-IeJ0CF3huY</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19813</th>\n",
       "      <td>yoga</td>\n",
       "      <td>-kSK2kqnTHA</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19814</th>\n",
       "      <td>yoga</td>\n",
       "      <td>0wHOYxjRmlw</td>\n",
       "      <td>41</td>\n",
       "      <td>51</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19860</th>\n",
       "      <td>zumba</td>\n",
       "      <td>0H5mnFcm2Kg</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     label   youtube_id  time_start  time_end split  is_cc\n",
       "0                abseiling  0wR5jVB-WPk         417       427   val      0\n",
       "50            air drumming  --nQbRBEz2s         104       114   val      0\n",
       "99     answering questions  -egPJubR-CE           1        11   val      0\n",
       "100    answering questions  -ejLPB4J4SM         106       116   val      0\n",
       "101    answering questions  -emx5qjikEc           1        11   val      0\n",
       "...                    ...          ...         ...       ...   ...    ...\n",
       "19811                 yoga  -Gb1pbOE32g          32        42   val      0\n",
       "19812                 yoga  -IeJ0CF3huY          16        26   val      0\n",
       "19813                 yoga  -kSK2kqnTHA          22        32   val      0\n",
       "19814                 yoga  0wHOYxjRmlw          41        51   val      1\n",
       "19860                zumba  0H5mnFcm2Kg          17        27   val      0\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_videos_metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! Now we have a DataFrame with only 1000 rows -- one for each locally available video clip. What did we end up downloading? Let's take a look at what classes we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "massaging legs              10\n",
       "scrambling eggs              9\n",
       "massaging person's head      8\n",
       "eating chips                 8\n",
       "folding paper                7\n",
       "                            ..\n",
       "lunge                        1\n",
       "massaging feet               1\n",
       "punching person (boxing)     1\n",
       "blowing out candles          1\n",
       "pumping fist                 1\n",
       "Name: label, Length: 360, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_videos_metadata_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 400 unique classes, we have videos from 360 of those. Most classes only have one representative video clip, though we do have a handful of video clips from classes like \"massaging legs,\" and \"scrambling eggs.\" \n",
    "\n",
    "Video classification is computationally expensive so in the following cell we take a small, random sample of vidoes to explore for the remainder of this notebook. Because this is a random sample, each time you run this cell you'll get a new set of 8 videos to play with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>youtube_id</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "      <th>split</th>\n",
       "      <th>is_cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>parkour</td>\n",
       "      <td>-6KNHzXeYKo</td>\n",
       "      <td>173</td>\n",
       "      <td>183</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>brushing hair</td>\n",
       "      <td>-Gio3hF5OA0</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5923</th>\n",
       "      <td>exercising arm</td>\n",
       "      <td>0wZpjStZtUY</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>eating cake</td>\n",
       "      <td>0pQACKjlllc</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>braiding hair</td>\n",
       "      <td>0uswr636GWs</td>\n",
       "      <td>57</td>\n",
       "      <td>67</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17866</th>\n",
       "      <td>tickling</td>\n",
       "      <td>-JuFFz7KyMo</td>\n",
       "      <td>41</td>\n",
       "      <td>51</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>playing flute</td>\n",
       "      <td>-SdDjLIkBHc</td>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>extinguishing fire</td>\n",
       "      <td>-X1Allr_ZcY</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    label   youtube_id  time_start  time_end split  is_cc\n",
       "10302             parkour  -6KNHzXeYKo         173       183   val      0\n",
       "1796        brushing hair  -Gio3hF5OA0          36        46   val      0\n",
       "5923       exercising arm  0wZpjStZtUY           1        11   val      0\n",
       "5471          eating cake  0pQACKjlllc           2        12   val      0\n",
       "1599        braiding hair  0uswr636GWs          57        67   val      0\n",
       "17866            tickling  -JuFFz7KyMo          41        51   val      0\n",
       "11499       playing flute  -SdDjLIkBHc          43        53   val      0\n",
       "6018   extinguishing fire  -X1Allr_ZcY          15        25   val      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_VIDEOS = 8\n",
    "\n",
    "video_sample = available_videos_metadata_df.sample(NUM_VIDEOS)\n",
    "video_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! We've selected a manageable batch of just 8 videos to examine. And we can see at a glance which classes our model will be attempting to predict. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIjAyFxDZ68P"
   },
   "source": [
    "###  Visualize some videos\n",
    "\n",
    "So what kind of videos are we dealing with?  In the cell below we display our video clip sample along with their ground truth class labels. As you play each video, notice that each is only approximately ten seconds long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JTKIGevPEin5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr>\n",
       "            <td><h2>0</h2><p>parkour</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/-6KNHzXeYKo_000173_000183.mp4 type=\"video/mp4\">\n",
       "            </video></td>\n",
       "            <td><h2>1</h2><p>brushing hair</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/-Gio3hF5OA0_000036_000046.mp4 type=\"video/mp4\">\n",
       "            </video></td>\n",
       "            <td><h2>2</h2><p>exercising arm</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/0wZpjStZtUY_000001_000011.mp4 type=\"video/mp4\">\n",
       "            </video></td>\n",
       "            <td><h2>3</h2><p>eating cake</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/0pQACKjlllc_000002_000012.mp4 type=\"video/mp4\">\n",
       "            </video></td></tr><tr>\n",
       "            <td><h2>4</h2><p>braiding hair</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/0uswr636GWs_000057_000067.mp4 type=\"video/mp4\">\n",
       "            </video></td>\n",
       "            <td><h2>5</h2><p>tickling</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/-JuFFz7KyMo_000041_000051.mp4 type=\"video/mp4\">\n",
       "            </video></td>\n",
       "            <td><h2>6</h2><p>playing flute</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/-SdDjLIkBHc_000043_000053.mp4 type=\"video/mp4\">\n",
       "            </video></td>\n",
       "            <td><h2>7</h2><p>extinguishing fire</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/-X1Allr_ZcY_000015_000025.mp4 type=\"video/mp4\">\n",
       "            </video></td></tr><tr></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_html = make_video_table(video_sample['youtube_id'].values, video_sample['label'].values)\n",
    "display.HTML(video_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpM3SmEf7JuN"
   },
   "source": [
    "### Pre-processing\n",
    "\n",
    "Now that we have a sense of what kind of videos we're working with, let's start classifying them! But before we do that, we have another step to perform -- preprocessing.  \n",
    "\n",
    "The YouTube videos in the Kinetics dataset are all in `.mp4` format but TensorFlow models do not recognize this! We must convert the videos into a format that our TF model can work with. This requires two steps: \n",
    "1. convert the `.mp4` format to a more appropriate data structure, like NumPy arrays\n",
    "2. Resize the video dimensions to work within model specifications\n",
    "\n",
    "####  Video resizing \n",
    "While the first step is likely self-explanatory, the second step deserves some attention. Those with experience working with pre-trained image classification models are likely already familiar with the idea that these models require image inputs of a specific height and width. These requirements are determined during model training and set limits on how large (or small) an image must be in pixels in order for the model to process that image. Video classification is no different in this respect, but comes with a third dimension of complexity: time. \n",
    "\n",
    "Let's take a look at the dimensions of the videos in our sample batch. The following cells will read an `.mp4` video clip into a numpy array and print the shape of that array to the screen. The shape tuple has the following format: \n",
    "\n",
    "(number of frames, height in pixels, width in pixels, number of color channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path):\n",
    "    \"\"\"Convert video to Numpy array.\"\"\"\n",
    "    import cv2\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()  # frame is in BGR format\n",
    "            if not ret:\n",
    "                break\n",
    "            frames.append(frame)\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 240, 320, 3)\n",
      "(300, 360, 480, 3)\n",
      "(234, 320, 568, 3)\n",
      "(258, 360, 202, 3)\n",
      "(300, 360, 480, 3)\n",
      "(300, 320, 568, 3)\n",
      "(300, 360, 486, 3)\n",
      "(300, 720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "video_paths = [glob.glob(f\"{pathname}/{yt_id}*\")[0] for yt_id in video_sample['youtube_id'].values]\n",
    "\n",
    "for video_path in video_paths: \n",
    "    video_np = load_video(video_path)\n",
    "    print(video_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there's quite a bit of variation among our video batch that isn't really detectable when we viewed the raw video clips earlier. While each video is exactly 10 seconds long, some have 300 frames and others have only 127 frames. Some have small spatial dimensions (240 x 320) while others are quite large (720 x 1280). The only thing common to all videos is that they each have three color channels, the familiar RGB system. \n",
    "\n",
    "This has implications for how we sample and process these video clips for model consumption. The model we'll use in this notebook requires spatial dimensions of (224 x 224) so we'll need to resize and crop each frame of each video to these dimensions. \n",
    "\n",
    "But how do we deal with the temporal dimension, i.e., the number of frames?  That depends on how we want to use our video classification model. The model has no specified limit on the number of frames it can accept (note, however, that more frames translates to longer processing time which can become very computationally expensive!) If we only send to the model one video clip at a time, we can feed it the full number of frames for inference. However, it's usually faster to send a batch to the model rather than sending each video separately. In that case, we need to deal with the variation in frame rates for these videos because we cannot create a numpy array in which one of the dimesions varies!  \n",
    "\n",
    "#### Video Resampling\n",
    "The crux of the issue lies in the fact that different cameras have different frame capture rates. Higher quality videos have more frames-per-second (FPS) than lower quality videos leading to a situation in which a collection of 10 second videos can nevertheles have different numbers of frames. Below we show a toy example of two videos that are each 10 seconds long but the top fewer frames than the bottom one over that time span due to having a lower FPS.   \n",
    "\n",
    "![Upsampling](images/video_fps_example.jpg)\n",
    "\n",
    "In order to create a batch of video clips, we must resample the clips so that each has the same number of frames.  This can be accomplished either by _upsampling_ videos with low FPS, or _downsampling_ videos with high FPS.  A simple way to perform upsampling is to duplicate certain frames throughout the length of the video. In the figure below, we see Video 1 has frames added to match the number of frames contained in Video 2.  These frames are duplicates of existing frames in Video 1 (which is why some of the frames are repeated colors). \n",
    "\n",
    "<img src=\"images/upsample.gif\">\n",
    "\n",
    "In contrast, downsampling involves removing frames periodically throughout the video. This time, we remove a sample of unique frames from Video 2 so that it has the same number of frames as Video 1. \n",
    "<img src = \"images/downsample.gif\">\n",
    "\n",
    "In either case, resampling should be done in such a way that the frames we duplicate or remove are equally dispersed throughout the duration of the 10 second clip in order to capture as much of the original motion as possible. \n",
    "\n",
    "In a pinch we could simply grab a fixed-size chunk of consecutive frames (from the beginning, middle, or end) from each video clip. The problem here is that this chunk may only represent a portion of the full 10 second interval. The model would then attempt to infer on a batch of videos in which one of them has frames representing close to the full 10 seconds, while another has frames representing only a fraction of the time. This could increase the difficulty of the model to properly classify the latter video.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load videos into NumPy arrays\n",
    "\n",
    "Luckily, our `KineticsLoader` class has a `load_videos` method, similar to the one above, that also handles these pre-processing steps. Here's what we do under the hood:\n",
    "\n",
    "1. First, a central square proportional to the size of the video is cropped\n",
    "2. The cropped portion is resized to 224x224 pixels\n",
    "3. Videos are resampled \n",
    "   - If the user provides `num_frames`, all videos are resampled to have this many frames (upsampling those that have lower FPS, downsampling those with higher FPS)\n",
    "   - If `num_frames` is not provided, the algorithm determines which video in the batch has the lowest FPS (fewest frames) and all vidoes are downsampled to match this frame rate\n",
    "   \n",
    "\n",
    "Again we note that video clips with more total frames will take longer to process through the model. For the current dataset, `num_frames = 128` is reasonable choice.  For reference, the maximum number of frames that we've seen in the dataset is 300 (30 FPS). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_videos(youtube_ids, num_frames):\n",
    "    \"\"\"Create numpy array with batch of videos from list of youtube ids\"\"\",\n",
    "    # we created this list of video pathnames in an earlier cell\n",
    "    global video_paths\n",
    "    \n",
    "    video_batch = []\n",
    "    for video_path in video_paths:\n",
    "        video_np = load_and_resize_video(video_path, resize_type=\"crop\")\n",
    "        video_np = np.expand_dims(video_np, axis=0)\n",
    "        video_batch.append(video_np)\n",
    "            \n",
    "    video_batch_resampled = []\n",
    "    for video in video_batch:\n",
    "        resampled_video = resample_video(video, num_frames)\n",
    "        video_batch_resampled.append(resampled_video)\n",
    "            \n",
    "    return np.concatenate(video_batch_resampled, axis=0).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LbyopvjpwaTk"
   },
   "outputs": [],
   "source": [
    "num_frames = 128   \n",
    "videos_tensor = load_videos(video_sample['youtube_id'].values, num_frames=num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 128, 224, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a batch of 8 video clips in a format that our model will understand. \n",
    "\n",
    "It's time to classify!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "In this notebook we make use of the Inflated 3D ConvNet (I3D) video classification model. This model architecture was introduced in 2017 and provided state-of-the-art results for video action classification for multiple datasets. We dig into some of the details about the architecture and training for this model in our accompanying blog post [TODO: Link in January]. You can also read more about this model in the original paper, [Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset](https://arxiv.org/abs/1705.07750). \n",
    "\n",
    "Since it's inception, there are now multiple pre-trained versions of the I3D model that are publicly available on the [TensorFlow Model Hub](https://www.tensorflow.org/hub). The original version was pre-trained on the Kinetics 400 dataset, which we explored above. Another version was trained on the Kinetics 600 dataset. We created an `I3DLoader` class to handle model loading from the TF Model Hub. You can choose either the `kinetics-400` or `kinetics-600` version. \n",
    "\n",
    "The biggest difference between these two models is in the number of classes they predict. I3D trained on Kinetics 400 predicts, you guessed it, 400 different classes, while it's counterpart (I3D trained on Kinetics 600) predicts on 600 classes. While we didn't discuss the Kinetics 600 dataset in detail, it is essentially a superset of the Kinetics 400 dataset -- it includes all 400 labels from that dataset, plus an additional 200 unique classes. Either can be used to make inference on our sample of videos but keep in mind that with more classes comes more challenges in predicting the correct class -- there are simply more options for the model to choose from. \n",
    "\n",
    "Below we load up the I3D model trained on the Kinetics 400 dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "mYei3gz4D-1O"
   },
   "outputs": [],
   "source": [
    "i3d400 = I3DLoader(trained_on='kinetics-400')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what kinds of predictions this model can make. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abseiling',\n",
       " 'air drumming',\n",
       " 'answering questions',\n",
       " 'applauding',\n",
       " 'applying cream',\n",
       " 'archery',\n",
       " 'arm wrestling',\n",
       " 'arranging flowers',\n",
       " 'assembling computer',\n",
       " 'auctioning',\n",
       " 'baby waking up',\n",
       " 'baking cookies',\n",
       " 'balloon blowing',\n",
       " 'bandaging',\n",
       " 'barbequing',\n",
       " 'bartending',\n",
       " 'beatboxing',\n",
       " 'bee keeping',\n",
       " 'belly dancing',\n",
       " 'bench pressing']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i3d400.labels[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model predictions\n",
    "\n",
    "Now that we have data in the proper format, ground truth labels, and a model loaded and ready to go -- it's time to make predictions! This notebook was developed on CPUs so the following cell can take some time to run. One way to speed up inference is to resample the vidoes to each have fewer frames, as we discussed above. The downside is that performance will likely degrade since the model will have fewer frames on which to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "eRCresdXShW3"
   },
   "outputs": [],
   "source": [
    "scores, predictions, _, _ = predict(videos_tensor, i3d400, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of our `predict` function includes the probabilities associated with each of the 400 labels and the 400 labels themselves for each video clip in our batch, sorted in descending order so that the most likely classes (highest probabilities) are at the top of the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['parkour', 'hopscotch', 'skateboarding', ..., 'filling eyebrows',\n",
       "        'grinding meat', 'knitting'],\n",
       "       ['headbanging', 'air drumming', 'pumping fist', ...,\n",
       "        'weaving basket', 'bookbinding', 'skiing slalom'],\n",
       "       ['exercising arm', 'lunge', 'squat', ..., 'paragliding',\n",
       "        'biking through snow', 'bee keeping'],\n",
       "       ...,\n",
       "       ['waxing chest', 'waxing back', 'waxing legs', ...,\n",
       "        'skiing crosscountry', 'golf chipping', 'golf driving'],\n",
       "       ['playing flute', 'playing bass guitar', 'playing clarinet', ...,\n",
       "        'baby waking up', 'golf chipping', 'washing feet'],\n",
       "       ['extinguishing fire', 'motorcycling', 'walking the dog', ...,\n",
       "        'assembling computer', 'waxing chest', 'getting a tattoo']],\n",
       "      dtype='<U39')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.7998241e-01, 1.9977430e-01, 1.1454046e-01, ..., 4.1070369e-09,\n",
       "        4.0600794e-09, 5.2552024e-10],\n",
       "       [4.4746959e-01, 1.3770965e-01, 7.1373403e-02, ..., 3.1191104e-07,\n",
       "        1.9676860e-07, 9.9010187e-08],\n",
       "       [8.8977093e-01, 7.2920687e-02, 1.6560765e-02, ..., 5.9105013e-12,\n",
       "        5.4985903e-12, 1.6751210e-12],\n",
       "       ...,\n",
       "       [7.2241563e-01, 1.0739921e-01, 8.9139961e-02, ..., 4.2127171e-10,\n",
       "        4.0363674e-10, 1.1107539e-10],\n",
       "       [9.9448818e-01, 2.4768533e-03, 7.9978246e-04, ..., 6.6125674e-11,\n",
       "        4.2203865e-11, 1.0055722e-11],\n",
       "       [8.2344991e-01, 4.8134100e-02, 1.8919127e-02, ..., 9.7456706e-08,\n",
       "        4.7469481e-08, 5.2609685e-09]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store our results as a Pandas DataFrame to make it easier to work with. This dataframe keeps only the top five model predictions for each video. The `Video_Id` index refers to the numbering of the vidoes in our visualize section above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rG2INvv6TjpY"
   },
   "outputs": [],
   "source": [
    "# collect metadata and model results\n",
    "results = defaultdict(list)\n",
    "\n",
    "results['YouTube_Id'] = video_sample['youtube_id'].values\n",
    "results['Ground_Truth'] = video_sample['label'].values\n",
    "\n",
    "for s, p in zip(scores, predictions):\n",
    "    results['scores'].append(list(s[:5]))\n",
    "    results['preds'].append(list(p[:5]))\n",
    "\n",
    "results_df = store_results_in_dataframe(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YouTube_Id</th>\n",
       "      <th>Ground_Truth</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6KNHzXeYKo</td>\n",
       "      <td>parkour</td>\n",
       "      <td>parkour</td>\n",
       "      <td>hopscotch</td>\n",
       "      <td>skateboarding</td>\n",
       "      <td>playing cricket</td>\n",
       "      <td>krumping</td>\n",
       "      <td>0.379982</td>\n",
       "      <td>0.199774</td>\n",
       "      <td>0.114540</td>\n",
       "      <td>0.093412</td>\n",
       "      <td>0.075015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-Gio3hF5OA0</td>\n",
       "      <td>brushing hair</td>\n",
       "      <td>headbanging</td>\n",
       "      <td>air drumming</td>\n",
       "      <td>pumping fist</td>\n",
       "      <td>beatboxing</td>\n",
       "      <td>slapping</td>\n",
       "      <td>0.447470</td>\n",
       "      <td>0.137710</td>\n",
       "      <td>0.071373</td>\n",
       "      <td>0.042713</td>\n",
       "      <td>0.028393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0wZpjStZtUY</td>\n",
       "      <td>exercising arm</td>\n",
       "      <td>exercising arm</td>\n",
       "      <td>lunge</td>\n",
       "      <td>squat</td>\n",
       "      <td>exercising with an exercise ball</td>\n",
       "      <td>front raises</td>\n",
       "      <td>0.889771</td>\n",
       "      <td>0.072921</td>\n",
       "      <td>0.016561</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.003058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0pQACKjlllc</td>\n",
       "      <td>eating cake</td>\n",
       "      <td>eating ice cream</td>\n",
       "      <td>eating spaghetti</td>\n",
       "      <td>eating cake</td>\n",
       "      <td>blowing nose</td>\n",
       "      <td>laughing</td>\n",
       "      <td>0.348714</td>\n",
       "      <td>0.138570</td>\n",
       "      <td>0.119416</td>\n",
       "      <td>0.054775</td>\n",
       "      <td>0.048254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0uswr636GWs</td>\n",
       "      <td>braiding hair</td>\n",
       "      <td>braiding hair</td>\n",
       "      <td>curling hair</td>\n",
       "      <td>fixing hair</td>\n",
       "      <td>dying hair</td>\n",
       "      <td>washing hair</td>\n",
       "      <td>0.859741</td>\n",
       "      <td>0.133039</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-JuFFz7KyMo</td>\n",
       "      <td>tickling</td>\n",
       "      <td>waxing chest</td>\n",
       "      <td>waxing back</td>\n",
       "      <td>waxing legs</td>\n",
       "      <td>bandaging</td>\n",
       "      <td>tickling</td>\n",
       "      <td>0.722416</td>\n",
       "      <td>0.107399</td>\n",
       "      <td>0.089140</td>\n",
       "      <td>0.036302</td>\n",
       "      <td>0.019120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-SdDjLIkBHc</td>\n",
       "      <td>playing flute</td>\n",
       "      <td>playing flute</td>\n",
       "      <td>playing bass guitar</td>\n",
       "      <td>playing clarinet</td>\n",
       "      <td>playing trumpet</td>\n",
       "      <td>playing guitar</td>\n",
       "      <td>0.994488</td>\n",
       "      <td>0.002477</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-X1Allr_ZcY</td>\n",
       "      <td>extinguishing fire</td>\n",
       "      <td>extinguishing fire</td>\n",
       "      <td>motorcycling</td>\n",
       "      <td>walking the dog</td>\n",
       "      <td>pushing car</td>\n",
       "      <td>jogging</td>\n",
       "      <td>0.823450</td>\n",
       "      <td>0.048134</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.014241</td>\n",
       "      <td>0.010791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           YouTube_Id        Ground_Truth              pred_1  \\\n",
       "video_id                                                        \n",
       "0         -6KNHzXeYKo             parkour             parkour   \n",
       "1         -Gio3hF5OA0       brushing hair         headbanging   \n",
       "2         0wZpjStZtUY      exercising arm      exercising arm   \n",
       "3         0pQACKjlllc         eating cake    eating ice cream   \n",
       "4         0uswr636GWs       braiding hair       braiding hair   \n",
       "5         -JuFFz7KyMo            tickling        waxing chest   \n",
       "6         -SdDjLIkBHc       playing flute       playing flute   \n",
       "7         -X1Allr_ZcY  extinguishing fire  extinguishing fire   \n",
       "\n",
       "                       pred_2            pred_3  \\\n",
       "video_id                                          \n",
       "0                   hopscotch     skateboarding   \n",
       "1                air drumming      pumping fist   \n",
       "2                       lunge             squat   \n",
       "3            eating spaghetti       eating cake   \n",
       "4                curling hair       fixing hair   \n",
       "5                 waxing back       waxing legs   \n",
       "6         playing bass guitar  playing clarinet   \n",
       "7                motorcycling   walking the dog   \n",
       "\n",
       "                                    pred_4          pred_5   score_1  \\\n",
       "video_id                                                               \n",
       "0                          playing cricket        krumping  0.379982   \n",
       "1                               beatboxing        slapping  0.447470   \n",
       "2         exercising with an exercise ball    front raises  0.889771   \n",
       "3                             blowing nose        laughing  0.348714   \n",
       "4                               dying hair    washing hair  0.859741   \n",
       "5                                bandaging        tickling  0.722416   \n",
       "6                          playing trumpet  playing guitar  0.994488   \n",
       "7                              pushing car         jogging  0.823450   \n",
       "\n",
       "           score_2   score_3   score_4   score_5  \n",
       "video_id                                          \n",
       "0         0.199774  0.114540  0.093412  0.075015  \n",
       "1         0.137710  0.071373  0.042713  0.028393  \n",
       "2         0.072921  0.016561  0.004367  0.003058  \n",
       "3         0.138570  0.119416  0.054775  0.048254  \n",
       "4         0.133039  0.006605  0.000457  0.000152  \n",
       "5         0.107399  0.089140  0.036302  0.019120  \n",
       "6         0.002477  0.000800  0.000674  0.000506  \n",
       "7         0.048134  0.018919  0.014241  0.010791  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "So how well did our model do?  It may seem natural to consider the model's accuracy using only it's top prediction for each video and we'll look at that first. However, when working with hundreds of classes, subtlties arise. For example, some classes could be easily confused -- \"catching or throwing a softball\" and \"catching or throwing a baseball\" are both classes but it may be difficult for the model to discern the type of ball in a low quality video or if the ball only takes up a small handful of pixels in a wide-shot video.  Additionaly, videos can contain more than one action -- \"texting\" while \"driving a car\" (don't do that!) or \"hula hooping\" while \"playing ukulele\". The Kinetics 400 dataset only provides a single ground-truth label for each video, rather than an exhaustive list of annotations. For this reason, the authors recommend evaluating model performance on the top-5 accuracy, rather than top-1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize videos again\n",
    "\n",
    "Let's first examine the model's top-1 accuracy by considering our video visualization. Our visualization helper function can also accept and display the model's top prediction beneath each video. If the model's prediction does not match the ground truth label, the text will display red. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr>\n",
       "            <td><h2>0</h2><p>parkour</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/-6KNHzXeYKo_000173_000183.mp4 type=\"video/mp4\">\n",
       "            </video><p style='color:black;'>parkour</p></td>\n",
       "            <td><h2>1</h2><p>brushing hair</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/-Gio3hF5OA0_000036_000046.mp4 type=\"video/mp4\">\n",
       "            </video><p style='color:red;'>headbanging</p></td>\n",
       "            <td><h2>2</h2><p>exercising arm</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/0wZpjStZtUY_000001_000011.mp4 type=\"video/mp4\">\n",
       "            </video><p style='color:black;'>exercising arm</p></td>\n",
       "            <td><h2>3</h2><p>eating cake</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/0pQACKjlllc_000002_000012.mp4 type=\"video/mp4\">\n",
       "            </video><p style='color:red;'>eating ice cream</p></td></tr><tr>\n",
       "            <td><h2>4</h2><p>braiding hair</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/0uswr636GWs_000057_000067.mp4 type=\"video/mp4\">\n",
       "            </video><p style='color:black;'>braiding hair</p></td>\n",
       "            <td><h2>5</h2><p>tickling</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/-JuFFz7KyMo_000041_000051.mp4 type=\"video/mp4\">\n",
       "            </video><p style='color:red;'>waxing chest</p></td>\n",
       "            <td><h2>6</h2><p>playing flute</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/-SdDjLIkBHc_000043_000053.mp4 type=\"video/mp4\">\n",
       "            </video><p style='color:black;'>playing flute</p></td>\n",
       "            <td><h2>7</h2><p>extinguishing fire</p><video width=\"210\" height=\"140\" controls> \n",
       "                <source src=drive/MyDrive/video_classification/datasets/kinetics/400/val/part_0/-X1Allr_ZcY_000015_000025.mp4 type=\"video/mp4\">\n",
       "            </video><p style='color:black;'>extinguishing fire</p></td></tr><tr></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_html = make_video_table(results_df['YouTube_Id'], results_df['Ground_Truth'], results_df['pred_1'])\n",
    "display.HTML(video_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it may seem alarming that many of these texts are red, consider them in light of the discussion above -- how many of these top-1 labels might be a reasonable description of the video clip, even if it doesn't match the ground truth label? Are any of these labels possible points of confusion or are their multiple actions in the scene? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model accuracy on our very small sample\n",
    "\n",
    "Finally, let's consider the top-5 accuracy. In this case, we score the model as being \"correct\" if the ground truth label is within the model's top-5 predictions for a given video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-FHr8nDVl_9j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-1 accuracy: 62.50%\n",
      "top-5 accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "#This cell also doesn't run until prediction_df is addressed\n",
    "accuracy_top_1 = compute_accuracy(results_df, num_top_classes = 1)\n",
    "accuracy_top_5 = compute_accuracy(results_df, num_top_classes = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model's accuracy improves when we consider the top-5 predictions. While this approach doesn't always make sense for every circumstance, due to the nature of the Kinetics dataset and it's annotations, this method is certainly valid in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating over many videos\n",
    "\n",
    "So far, everything we've done has been to explore the capability of video classification with a small, concrete example. However, in practice, there are several models and many datasets that one might consider when building a real-world video classification application. In that case, one will need to evaluate dfferent models over various datasets in order to gauge which is most appropriate for the application in question. This is a model benchmarking job. To that end, we've created some additional utilities to facilitate model evaluation over a much larger portion of the Kinetics datasets. Included in this AMP is a benchmarking script that can be automated via the CML Jobs abstraction (or by a simple bash script, if that's your style). Here we provide a quick example of the core utilities contained within that script -- namely, the ability to load, pre-process, and batch over a larger portion of videos. \n",
    "\n",
    "We break this task into two parts: load and cache videos, and evaluation. The first step is performed by our `KineticsLoader` class, and does essentially the same steps as our `load_videos` function above. Specifically, this will load the raw `mp4` format into numpy arrays and perform essential pre-processing, such as cropping and resizing to I3D specifications. Once loaded, these video examples are cached (saved to disk) in their numpy format so that they can be reused in any downstream evaluation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed video already exists at /home/cdsw/data/processed/kinetics/400/val/part_0/0tlGOxUQ0Kw_000074_000084.pkl. Use overwrite=True to re-process.\n",
      "Processed video already exists at /home/cdsw/data/processed/kinetics/400/val/part_0/-05qSkAhM6Y_000205_000215.pkl. Use overwrite=True to re-process.\n",
      "Processed video already exists at /home/cdsw/data/processed/kinetics/400/val/part_0/-LISB_b8rIw_000049_000059.pkl. Use overwrite=True to re-process.\n",
      "Processed video already exists at /home/cdsw/data/processed/kinetics/400/val/part_0/--ILYNHl3e4_000541_000551.pkl. Use overwrite=True to re-process.\n",
      "Processed video already exists at /home/cdsw/data/processed/kinetics/400/val/part_0/-yv8c2CDbR8_000004_000014.pkl. Use overwrite=True to re-process.\n",
      "Processed video already exists at /home/cdsw/data/processed/kinetics/400/val/part_0/-aeOuOI3eN0_000219_000229.pkl. Use overwrite=True to re-process.\n",
      "Processed video already exists at /home/cdsw/data/processed/kinetics/400/val/part_0/-WZgMWx8Elk_000013_000023.pkl. Use overwrite=True to re-process.\n",
      "Processed video already exists at /home/cdsw/data/processed/kinetics/400/val/part_0/-Y-fUYGcb7o_000049_000059.pkl. Use overwrite=True to re-process.\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-beyXnxwTao_000040_000050.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-whdHn9Mbcc_000000_000010.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-CAPalSW0QI_000546_000556.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0HydDezkSU0_000018_000028.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-4hx9N2OhZo_000029_000039.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-PW6kckornM_000008_000018.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-Wx7UjNi3uU_000010_000020.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0dwPQPV3iYQ_000039_000049.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-0r6NmrdKCU_000043_000053.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0Lx_B0Xg3kU_000007_000017.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-5vr1M9jygc_000100_000110.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-AMpy1HyBfk_000261_000271.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-mhWqo41duA_000000_000010.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-sf01vs2YMg_000146_000156.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/00cwEcZZcu4_000003_000013.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-4JdZpx3zNk_000268_000278.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0d2XdZRy2fc_000003_000013.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/16nvBqBrrL0_000025_000035.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-C38_1dMytQ_000027_000037.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-RE0Mjs6Hdw_000000_000010.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0mX7eiHEiP8_000003_000013.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-9V1qe3Lk2M_000001_000011.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0N8szFGAmMw_000412_000422.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-W3DfTD7kYY_000000_000010.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-vxNdkgPqzg_000033_000043.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/018EClOtVTM_000035_000045.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-jPhOjjHIl0_000176_000186.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-bVVs-_nntQ_000056_000066.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-ApPJCMjZVg_000114_000124.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-owlUWS7Sds_000086_000096.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-1Hub6Ps_cc_000047_000057.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/031AhY-44lw_000003_000013.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0C6viKYd1B4_000051_000061.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-i1c-6xhoWk_000000_000010.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/--AbCB6WSN0_000018_000028.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0xAB67W5GS4_000969_000979.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0yNXOIqJLtA_000012_000022.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-5klnjYyA6o_000002_000012.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-INebMIVKyo_000005_000015.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-2csq_1UhMQ_000002_000012.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-02UO1KSdZ0_000025_000035.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-khmO1mLnoA_000143_000153.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/1-Gu8XdbVl8_000071_000081.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/--oJV4vFNeI_000003_000013.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-DtqvvSHdk4_000076_000086.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-kFCALWZ8dQ_000007_000017.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-2C-yeMmge0_000003_000013.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-5LEMasZdOc_000015_000025.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-UaSZJopmBk_000000_000010.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-DavtY9xgnc_000545_000555.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-3Ck7V6iqPk_000008_000018.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-dSUldceBAA_000031_000041.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/0Xt8zQ_UPq8_000026_000036.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-_hu_Ld-ddk_000007_000017.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/13Ub1MDkiHc_000014_000024.mp4\n",
      "Processing /home/cdsw/data/raw/kinetics/400/val/part_0/-1QTRLQSzhQ_000145_000155.mp4\n"
     ]
    }
   ],
   "source": [
    "num_videos = 64\n",
    "loader.load_and_cache_video_examples(num_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is an evaluation function that encapsulates all of the prediction steps we performed above. This function accepts a model and data loader class and infers on the requested number of videos, grouping them into the given `batch_size` after resampling to `num_frames` number of frames for each video. The results are stored in a Pandas DataFrame so that we can consider the overall model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = evaluate(\n",
    "    i3d400,\n",
    "    loader, \n",
    "    num_videos=num_videos, \n",
    "    batch_size=8, \n",
    "    top_n_results=5, \n",
    "    num_frames=100, \n",
    "    savefile=\"small_test_results_i3d.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YouTube_Id</th>\n",
       "      <th>Ground_Truth</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0mX7eiHEiP8</td>\n",
       "      <td>setting table</td>\n",
       "      <td>plastering</td>\n",
       "      <td>dancing macarena</td>\n",
       "      <td>playing cricket</td>\n",
       "      <td>cleaning toilet</td>\n",
       "      <td>crying</td>\n",
       "      <td>0.098597</td>\n",
       "      <td>0.065879</td>\n",
       "      <td>0.053389</td>\n",
       "      <td>3.668990e-02</td>\n",
       "      <td>3.604879e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00cwEcZZcu4</td>\n",
       "      <td>biking through snow</td>\n",
       "      <td>biking through snow</td>\n",
       "      <td>riding mountain bike</td>\n",
       "      <td>riding a bike</td>\n",
       "      <td>riding unicycle</td>\n",
       "      <td>crossing river</td>\n",
       "      <td>0.998980</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>1.514738e-06</td>\n",
       "      <td>1.504889e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-05qSkAhM6Y</td>\n",
       "      <td>belly dancing</td>\n",
       "      <td>belly dancing</td>\n",
       "      <td>contact juggling</td>\n",
       "      <td>hopscotch</td>\n",
       "      <td>plastering</td>\n",
       "      <td>tai chi</td>\n",
       "      <td>0.534826</td>\n",
       "      <td>0.063855</td>\n",
       "      <td>0.042720</td>\n",
       "      <td>2.927776e-02</td>\n",
       "      <td>2.311769e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0r6NmrdKCU</td>\n",
       "      <td>making tea</td>\n",
       "      <td>making tea</td>\n",
       "      <td>setting table</td>\n",
       "      <td>cleaning toilet</td>\n",
       "      <td>making a cake</td>\n",
       "      <td>shredding paper</td>\n",
       "      <td>0.527350</td>\n",
       "      <td>0.123318</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>6.867204e-02</td>\n",
       "      <td>3.120951e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>018EClOtVTM</td>\n",
       "      <td>situp</td>\n",
       "      <td>situp</td>\n",
       "      <td>exercising with an exercise ball</td>\n",
       "      <td>exercising arm</td>\n",
       "      <td>throwing ball</td>\n",
       "      <td>stretching arm</td>\n",
       "      <td>0.999537</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>5.420654e-05</td>\n",
       "      <td>1.453274e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0d2XdZRy2fc</td>\n",
       "      <td>catching or throwing baseball</td>\n",
       "      <td>high kick</td>\n",
       "      <td>shooting basketball</td>\n",
       "      <td>playing basketball</td>\n",
       "      <td>drop kicking</td>\n",
       "      <td>cheerleading</td>\n",
       "      <td>0.675819</td>\n",
       "      <td>0.082590</td>\n",
       "      <td>0.074438</td>\n",
       "      <td>3.088997e-02</td>\n",
       "      <td>2.110464e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-PW6kckornM</td>\n",
       "      <td>punching person (boxing)</td>\n",
       "      <td>punching person (boxing)</td>\n",
       "      <td>wrestling</td>\n",
       "      <td>headbutting</td>\n",
       "      <td>drop kicking</td>\n",
       "      <td>side kick</td>\n",
       "      <td>0.991211</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>7.463089e-04</td>\n",
       "      <td>6.455458e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0N8szFGAmMw</td>\n",
       "      <td>carving pumpkin</td>\n",
       "      <td>carving pumpkin</td>\n",
       "      <td>balloon blowing</td>\n",
       "      <td>making a cake</td>\n",
       "      <td>waxing legs</td>\n",
       "      <td>laughing</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>6.156522e-08</td>\n",
       "      <td>4.203142e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-9V1qe3Lk2M</td>\n",
       "      <td>exercising with an exercise ball</td>\n",
       "      <td>exercising with an exercise ball</td>\n",
       "      <td>headbutting</td>\n",
       "      <td>balloon blowing</td>\n",
       "      <td>pumping fist</td>\n",
       "      <td>drinking shots</td>\n",
       "      <td>0.501306</td>\n",
       "      <td>0.069354</td>\n",
       "      <td>0.061799</td>\n",
       "      <td>5.425986e-02</td>\n",
       "      <td>4.095884e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-5LEMasZdOc</td>\n",
       "      <td>digging</td>\n",
       "      <td>blasting sand</td>\n",
       "      <td>spraying</td>\n",
       "      <td>hopscotch</td>\n",
       "      <td>watering plants</td>\n",
       "      <td>blowing leaves</td>\n",
       "      <td>0.906689</td>\n",
       "      <td>0.033253</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>8.516103e-03</td>\n",
       "      <td>7.819586e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           YouTube_Id                      Ground_Truth  \\\n",
       "video_id                                                  \n",
       "0         0mX7eiHEiP8                     setting table   \n",
       "1         00cwEcZZcu4               biking through snow   \n",
       "2         -05qSkAhM6Y                     belly dancing   \n",
       "3         -0r6NmrdKCU                        making tea   \n",
       "4         018EClOtVTM                             situp   \n",
       "...               ...                               ...   \n",
       "59        0d2XdZRy2fc     catching or throwing baseball   \n",
       "60        -PW6kckornM          punching person (boxing)   \n",
       "61        0N8szFGAmMw                   carving pumpkin   \n",
       "62        -9V1qe3Lk2M  exercising with an exercise ball   \n",
       "63        -5LEMasZdOc                           digging   \n",
       "\n",
       "                                    pred_1                            pred_2  \\\n",
       "video_id                                                                       \n",
       "0                               plastering                  dancing macarena   \n",
       "1                      biking through snow              riding mountain bike   \n",
       "2                            belly dancing                  contact juggling   \n",
       "3                               making tea                     setting table   \n",
       "4                                    situp  exercising with an exercise ball   \n",
       "...                                    ...                               ...   \n",
       "59                               high kick               shooting basketball   \n",
       "60                punching person (boxing)                         wrestling   \n",
       "61                         carving pumpkin                   balloon blowing   \n",
       "62        exercising with an exercise ball                       headbutting   \n",
       "63                           blasting sand                          spraying   \n",
       "\n",
       "                      pred_3           pred_4           pred_5   score_1  \\\n",
       "video_id                                                                   \n",
       "0            playing cricket  cleaning toilet           crying  0.098597   \n",
       "1              riding a bike  riding unicycle   crossing river  0.998980   \n",
       "2                  hopscotch       plastering          tai chi  0.534826   \n",
       "3            cleaning toilet    making a cake  shredding paper  0.527350   \n",
       "4             exercising arm    throwing ball   stretching arm  0.999537   \n",
       "...                      ...              ...              ...       ...   \n",
       "59        playing basketball     drop kicking     cheerleading  0.675819   \n",
       "60               headbutting     drop kicking        side kick  0.991211   \n",
       "61             making a cake      waxing legs         laughing  0.999981   \n",
       "62           balloon blowing     pumping fist   drinking shots  0.501306   \n",
       "63                 hopscotch  watering plants   blowing leaves  0.906689   \n",
       "\n",
       "           score_2   score_3       score_4       score_5  \n",
       "video_id                                                  \n",
       "0         0.065879  0.053389  3.668990e-02  3.604879e-02  \n",
       "1         0.000945  0.000070  1.514738e-06  1.504889e-06  \n",
       "2         0.063855  0.042720  2.927776e-02  2.311769e-02  \n",
       "3         0.123318  0.079832  6.867204e-02  3.120951e-02  \n",
       "4         0.000294  0.000083  5.420654e-05  1.453274e-05  \n",
       "...            ...       ...           ...           ...  \n",
       "59        0.082590  0.074438  3.088997e-02  2.110464e-02  \n",
       "60        0.003232  0.003036  7.463089e-04  6.455458e-04  \n",
       "61        0.000011  0.000008  6.156522e-08  4.203142e-08  \n",
       "62        0.069354  0.061799  5.425986e-02  4.095884e-02  \n",
       "63        0.033253  0.012355  8.516103e-03  7.819586e-03  \n",
       "\n",
       "[64 rows x 12 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-1 accuracy: 56.25%\n",
      "top-5 accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy_top_1 = compute_accuracy(results_df, num_top_classes = 1)\n",
    "accuracy_top_5 = compute_accuracy(results_df, num_top_classes = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If this documentation includes code, including but not limited to, code examples, Cloudera makes this available to you under the terms of the Apache License, Version 2.0, including any required notices. A copy of the Apache License Version 2.0 can be found here.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "x8Q7Un821X1A"
   ],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "tf_action_recognition_UCF101_DAN",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
